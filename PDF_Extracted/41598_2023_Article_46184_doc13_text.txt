# Scientific Reports

# (2023) 13:19428

# www.nature.com/scientificreports/

benign or non-specific symptoms42. The IBDMDB website contains the raw and the final results of the processed information, the complete pipeline for producing the final results is:

1. Quality and error checking for completeness, producing raw files.
2. AnADAMA pipeline, producing products.

In particular, if we consider the pipeline for producing the metagenomic data, after stool collection, the samples for the quality control process go through the KneadData43 and the AnADAMA pipelines. The former is a tool useful to exclude the reads, which are fragments of DNA, related to the host or related to other contaminants from the metagenomic sequencing data, and this separation step is made completely in silico. Whereas the latter, the AnADAMA pipeline, performs and produces documents from an automated scientific workflow, where a workflow is simply a succession of tasks, such as quantifying operational taxonomic units (OTU). The OTUs are classifications of groups of bacteria closely related to each other by sequence similarity. On the IBDMDB website, there are two versions of data Version 2.0 and Version 3.0. Version 3.0 has been uploaded with the new version of bioBakery44. In our work, we use the products file related to the functional profiles Version 2.0. Moreover, we exploit the HMP2 Metadata file, containing the sample IDs, the subject IDs and the properties associated with each sample. The External ID is the unique ID of the sample, Participant ID is the subject from where the sample has been taken, diagnosis is either ulcerative colitis (UC), Crohn’s disease (CD) or control group (NI), week_num points out the week number, when the sample has been taken and data_type is the type of sample (metagenomics, 16S, etc.). we extracted useful information to avoid importing the whole database, and we selected only the samples from the first week (week 0). Moreover, the samples different from metagenomic ones were excluded. Finally, we dropped the samples from the same participant in week 0 and obtained a list of samples IDs that were present in both the metagenomic database and the HMP2 Metadata. The metagenomic database contains as row indexes the gene descriptors; specifically, the descriptor is composed of the pathway, genus and species (e.g., “ARO-PWY: chorismate biosynthesis I |g__Alistipes.s__Alistipes_finegoldii”). To generate the database, the algorithm HUMAnN232 has been used. The algorithm can be divided into three phases; firstly, the metagenomic sample is quickly analyzed to seek known species in the gut microbiome. The functional annotation of the identified pangenomes (i.e. the genome of a larger group of species) of the microbiome is concatenated to form a gene database of the sample. Secondly, using this database, the whole sample is aligned, meaning that statistics regarding the species and the genes are made, and unmapped reads are collected. Thirdly, the gene abundances are calculated, and they are combined with the metabolic network to determine the pathways in the microbial community.

To reduce the number of pathways present in the resulting network, we built the correlation matrices and the biadjacency matrices for the projected networks for three different groups of pathways based on quantiles; namely, one group for the pathways expressed in a percentage between 25% and 50% of the subjects (uncommon pathways), another group for those in the range between 50% and 75% (common pathways), and lastly a group for the pathways expressed in more than 75% (prevalent pathways). Originally, there were 953 nodes among the uncommon pathways. 43 nodes were disconnected from the rest of the network in the correlation networks, hence, we chose to exclude these pathways from our analysis in both the correlation and projected networks.

# Correlation Networks

Correlation networks are built from the following steps:

1. pairwise gene similarity score (correlation);
2. thresholding.

Normalization methods, correlation measures (Pearson or Spearman), significance and relevance are still debated45. In our work, we chose the Pearson correlation similar to Ref. 46.

To transform a correlation matrix into a correlation network, we used a thresholding method inspired by a brain network technique that was used to cut the least important edges and keep the significant relationships among the nodes, hence, we calculated the absolute value of the correlations, making the signs irrelevant. This method consists of increasing a cut-off threshold until the network connectivity breaks apart; because of this property, this cut-off threshold is also known as the percolation threshold. This method has been considered one of the most effective methods to maximise the information quantity kept by the network47. In our work, we started from a cut-off threshold of t = 0, and we used a bisection method to get to the percolation threshold. In the bisection method, we flattened the absolute values in the weighted adjacency matrix into a sorted array, chose the median value and used it as the new cut-off threshold, we calculated the connectivity of the graph built from the adjacency matrix having this cut-off threshold, finally, if we obtained a connected graph with the median value as a cut-off threshold, we used as the sorted array the upper half array, on the contrary, we used the lower half. The procedure was iterative until convergence which corresponded to an array with zero length or with the same head and same tail.

# Co-expression network from bipartite projected networks

Bipartite networks are graphs G = (U, V , E) where the nodes can be divided into two disjoint sets, U and V, and every edge in E links an element in U to an element in V. In our work, we designated with U the set of nodes representing the genes and with V the set of nodes representing the samples. We can find in E all the edges connecting the gene u to the sample v if the gene was over-expressed in the corresponding sample. We evaluated