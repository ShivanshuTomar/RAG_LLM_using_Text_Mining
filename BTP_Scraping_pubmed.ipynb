{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "2F40G8WUy63q"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import os\n",
        "import logging\n",
        "import random\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "U_Rc9YozzBzz"
      },
      "outputs": [],
      "source": [
        "base_url = 'https://www.ncbi.nlm.nih.gov'\n",
        "search_url = 'https://www.ncbi.nlm.nih.gov/pmc/?term=(Inflammatory Bowel Disease%5BTitle%5D)+AND+(Gut microbiome)'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "l4ddwghS1GAO"
      },
      "outputs": [],
      "source": [
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UMXlr8Jn1wPV"
      },
      "outputs": [],
      "source": [
        "user_agents = [\n",
        "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36',\n",
        "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:86.0) Gecko/20100101 Firefox/86.0',\n",
        "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36',\n",
        "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.3 Safari/605.1.15',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JX8gpInyzCb2"
      },
      "outputs": [],
      "source": [
        "def download_pdf(pdf_url, filename):\n",
        "    headers = {'User-Agent': random.choice(user_agents)}\n",
        "    try:\n",
        "        response = requests.get(pdf_url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Create the downloaded_pdfs folder in the current working directory if it doesn't exist\n",
        "        current_dir = os.getcwd()\n",
        "        downloaded_pdfs_dir = os.path.join(current_dir, 'downloaded_pdfs')\n",
        "        os.makedirs(downloaded_pdfs_dir, exist_ok=True)\n",
        "\n",
        "        file_path = os.path.join(downloaded_pdfs_dir, filename)\n",
        "        with open(file_path, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "        logger.warning(f\"Downloaded: {filename}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        logger.error(f\"Error downloading PDF: {pdf_url}\")\n",
        "        logger.error(str(e))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bgXVuuDjzztC"
      },
      "outputs": [],
      "source": [
        "def scrape_articles(url, retry_count=3, delay=5, max_pages=4, current_page=1):\n",
        "    headers = {'User-Agent': random.choice(user_agents)}\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        articles = soup.find_all('div', class_='rslt')\n",
        "\n",
        "        for article in articles:\n",
        "            article_url = base_url + article.find('a')['href']\n",
        "            logger.warning(f\"Article URL:{article_url}\")\n",
        "            retry_article = 3\n",
        "            while retry_article > 0:\n",
        "                try:\n",
        "                    article_response = requests.get(article_url, headers=headers)\n",
        "                    article_response.raise_for_status()\n",
        "                    article_soup = BeautifulSoup(article_response.text, 'html.parser')\n",
        "\n",
        "                    pdf_link = article_soup.find('a', href=re.compile(r'\\.pdf$'))\n",
        "\n",
        "                    if pdf_link:\n",
        "                        pdf_url = base_url + pdf_link['href']\n",
        "                        pdf_filename = pdf_link['href'].split('/')[-1]\n",
        "                        download_pdf(pdf_url, pdf_filename)\n",
        "                        logger.warning(f\"Downloaded: {pdf_filename}\")\n",
        "                    else:\n",
        "                        logger.warning(f\"No PDF found for: {article_url}\")\n",
        "\n",
        "                    time.sleep(5)  # Add a random delay between article requests\n",
        "                    break  # Break the loop if the request is successful\n",
        "                except (requests.exceptions.RequestException, ConnectionResetError) as e:\n",
        "                    logger.error(f\"Error processing article: {article_url}\")\n",
        "                    logger.error(str(e))\n",
        "                    retry_article -= 1\n",
        "                    if retry_article > 0:\n",
        "                        logger.warning(f\"Retrying article {article_url} in {delay} seconds...\")\n",
        "                        time.sleep(delay)\n",
        "                    else:\n",
        "                        logger.error(f\"Max retry attempts reached for article: {article_url}. Skipping.\")\n",
        "\n",
        "        if current_page < max_pages:\n",
        "            pagination = soup.find('div', class_='pagination')\n",
        "            next_link = pagination.find('a', class_ = 'active page_link next')\n",
        "            logger.warning(f\"Current page: {current_page}\")\n",
        "\n",
        "            if next_link:\n",
        "                next_page = int(next_link.get('page', '0'))\n",
        "                logger.warning(f\"Next page: {next_page}\")\n",
        "                if next_page > current_page:\n",
        "                    logger.info(f\"Moving to page {next_page}\")\n",
        "                    time.sleep(random.uniform(2, 5))  # Add a random delay before moving to the next page\n",
        "\n",
        "                    # Construct the URL for the next page\n",
        "                    next_url = f\"{search_url}&page={next_page}\"\n",
        "                    logger.warning (f\"Next URL:{next_url}\")\n",
        "\n",
        "                    scrape_articles(next_url, retry_count, delay, max_pages, next_page)\n",
        "\n",
        "    except (requests.exceptions.RequestException, ConnectionResetError) as e:\n",
        "        if retry_count > 0:\n",
        "            logger.warning(f\"Request error occurred. Retrying in {delay} seconds...\")\n",
        "            time.sleep(delay)\n",
        "            scrape_articles(url, retry_count - 1, delay)\n",
        "        else:\n",
        "            logger.error(\"Max retry attempts reached. Skipping this request.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dYTFk1ALpfz"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "B8HG7N5qz2rw",
        "outputId": "3f81b55c-b2c6-495e-d6ca-3f2b1e467325"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'find'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mscrape_articles\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_url\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[13], line 44\u001b[0m, in \u001b[0;36mscrape_articles\u001b[1;34m(url, retry_count, delay, max_pages, current_page)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_page \u001b[38;5;241m<\u001b[39m max_pages:\n\u001b[0;32m     43\u001b[0m     pagination \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpagination\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 44\u001b[0m     next_link \u001b[38;5;241m=\u001b[39m \u001b[43mpagination\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, attrs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNext page of results\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m     45\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent page: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_page\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m next_link:\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
          ]
        }
      ],
      "source": [
        "scrape_articles(search_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-05 19:38:23,955 - WARNING - Article URL:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9706134/\n",
            "2024-10-05 19:38:29,786 - WARNING - Downloaded: main.pdf\n",
            "2024-10-05 19:38:29,786 - WARNING - Downloaded: main.pdf\n",
            "2024-10-05 19:38:34,791 - WARNING - Article URL:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7615213/\n",
            "2024-10-05 19:38:39,981 - WARNING - Downloaded: mrr-2-4-35.pdf\n",
            "2024-10-05 19:38:39,984 - WARNING - Downloaded: mrr-2-4-35.pdf\n",
            "2024-10-05 19:38:44,987 - WARNING - Article URL:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6342642/\n",
            "2024-10-05 19:38:49,442 - WARNING - Downloaded: nihms-1510763.pdf\n",
            "2024-10-05 19:38:49,442 - WARNING - Downloaded: nihms-1510763.pdf\n",
            "2024-10-05 19:38:54,454 - WARNING - Article URL:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7012301/\n",
            "2024-10-05 19:38:59,735 - WARNING - Downloaded: izz242.pdf\n",
            "2024-10-05 19:38:59,751 - WARNING - Downloaded: izz242.pdf\n",
            "2024-10-05 19:39:04,753 - WARNING - Article URL:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7589214/\n",
            "2024-10-05 19:39:09,333 - WARNING - Downloaded: nutrients-12-03204.pdf\n",
            "2024-10-05 19:39:09,345 - WARNING - Downloaded: nutrients-12-03204.pdf\n",
            "2024-10-05 19:39:14,349 - WARNING - Article URL:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6521386/\n",
            "2024-10-05 19:39:19,325 - WARNING - Downloaded: 40168_2019_Article_689.pdf\n",
            "2024-10-05 19:39:19,325 - WARNING - Downloaded: 40168_2019_Article_689.pdf\n",
            "2024-10-05 19:39:24,331 - WARNING - Article URL:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6131705/\n",
            "2024-10-05 19:39:29,305 - WARNING - Downloaded: nihms-923484.pdf\n",
            "2024-10-05 19:39:29,317 - WARNING - Downloaded: nihms-923484.pdf\n",
            "2024-10-05 19:39:34,320 - WARNING - Article URL:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8942410/\n",
            "2024-10-05 19:39:39,600 - WARNING - Downloaded: KGMI_14_2046244.pdf\n",
            "2024-10-05 19:39:39,611 - WARNING - Downloaded: KGMI_14_2046244.pdf\n",
            "2024-10-05 19:39:44,613 - WARNING - Article URL:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9280206/\n",
            "2024-10-05 19:39:49,256 - WARNING - Downloaded: main.pdf\n",
            "2024-10-05 19:39:49,274 - WARNING - Downloaded: main.pdf\n",
            "2024-10-05 19:39:54,276 - WARNING - Article URL:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8147118/\n",
            "2024-10-05 19:40:00,273 - WARNING - Downloaded: microorganisms-09-00977.pdf\n",
            "2024-10-05 19:40:00,276 - WARNING - Downloaded: microorganisms-09-00977.pdf\n",
            "2024-10-05 19:40:05,278 - WARNING - Article URL:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10928503/\n",
            "2024-10-05 19:40:10,533 - WARNING - Downloaded: nihms-1962152.pdf\n",
            "2024-10-05 19:40:10,533 - WARNING - Downloaded: nihms-1962152.pdf\n",
            "2024-10-05 19:40:15,541 - WARNING - Article URL:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8745446/\n",
            "2024-10-05 19:40:27,223 - WARNING - Downloaded: ijms-23-00206.pdf\n",
            "2024-10-05 19:40:27,223 - WARNING - Downloaded: ijms-23-00206.pdf\n",
            "2024-10-05 19:40:32,230 - WARNING - Article URL:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9247841/\n",
            "2024-10-05 19:40:36,538 - WARNING - Downloaded: izab343.pdf\n",
            "2024-10-05 19:40:36,543 - WARNING - Downloaded: izab343.pdf\n",
            "2024-10-05 19:40:41,545 - WARNING - Article URL:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8406238/\n",
            "2024-10-05 19:40:48,408 - WARNING - Downloaded: mbio.00975-21.pdf\n",
            "2024-10-05 19:40:48,408 - WARNING - Downloaded: mbio.00975-21.pdf\n",
            "2024-10-05 19:40:53,413 - WARNING - Article URL:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5319707/\n",
            "2024-10-05 19:40:57,599 - WARNING - Downloaded: nihms841832.pdf\n",
            "2024-10-05 19:40:57,599 - WARNING - Downloaded: nihms841832.pdf\n",
            "2024-10-05 19:41:02,612 - WARNING - Article URL:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9752296/\n",
            "2024-10-05 19:41:06,830 - WARNING - Downloaded: UEG2-10-1091.pdf\n",
            "2024-10-05 19:41:06,847 - WARNING - Downloaded: UEG2-10-1091.pdf\n",
            "2024-10-05 19:41:11,850 - WARNING - Article URL:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11150004/\n",
            "2024-10-05 19:41:16,292 - WARNING - Downloaded: nihms-1994547.pdf\n",
            "2024-10-05 19:41:16,308 - WARNING - Downloaded: nihms-1994547.pdf\n",
            "2024-10-05 19:41:21,312 - WARNING - Article URL:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8047854/\n",
            "2024-10-05 19:41:40,479 - WARNING - Downloaded: izaa262.pdf\n",
            "2024-10-05 19:41:40,495 - WARNING - Downloaded: izaa262.pdf\n",
            "2024-10-05 19:41:45,497 - WARNING - Article URL:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6759048/\n",
            "2024-10-05 19:41:49,990 - WARNING - Downloaded: nihms-1050393.pdf\n",
            "2024-10-05 19:41:49,990 - WARNING - Downloaded: nihms-1050393.pdf\n",
            "2024-10-05 19:41:55,001 - WARNING - Article URL:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10030733/\n",
            "2024-10-05 19:41:59,767 - WARNING - Downloaded: 12079_2022_Article_695.pdf\n",
            "2024-10-05 19:41:59,768 - WARNING - Downloaded: 12079_2022_Article_695.pdf\n",
            "2024-10-05 19:42:04,772 - WARNING - Current page: 1\n",
            "2024-10-05 19:42:04,772 - WARNING - Next page: 2\n",
            "2024-10-05 19:42:04,774 - WARNING - Next URL: https://www.ncbi.nlm.nih.gov/pmc/?term=(Inflammatory+Bowel+Disease%5BTitle%5D)+AND+(Gut+microbiome)&page=2\n",
            "2024-10-05 19:42:13,084 - WARNING - Article URL:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9706134/\n",
            "2024-10-05 19:42:18,942 - WARNING - Downloaded: main.pdf\n",
            "2024-10-05 19:42:18,942 - WARNING - Downloaded: main.pdf\n",
            "2024-10-05 19:42:23,954 - WARNING - Article URL:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7615213/\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[32], line 102\u001b[0m\n\u001b[0;32m     99\u001b[0m             logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMax retry attempts reached. Skipping this request.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Start scraping\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m \u001b[43mscrape_articles\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_url\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[32], line 91\u001b[0m, in \u001b[0;36mscrape_articles\u001b[1;34m(url, retry_count, delay, max_pages, current_page)\u001b[0m\n\u001b[0;32m     88\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNext URL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnext_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     90\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(random\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m))  \u001b[38;5;66;03m# Add a random delay before moving to the next page\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m         \u001b[43mscrape_articles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_pages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_page\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRequestException, \u001b[38;5;167;01mConnectionResetError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retry_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "Cell \u001b[1;32mIn[32], line 54\u001b[0m, in \u001b[0;36mscrape_articles\u001b[1;34m(url, retry_count, delay, max_pages, current_page)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m retry_article \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m         article_response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43marticle_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m         article_response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m     56\u001b[0m         article_soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(article_response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[1;32me:\\Anaconda\\envs\\BTP\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32me:\\Anaconda\\envs\\BTP\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32me:\\Anaconda\\envs\\BTP\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "File \u001b[1;32me:\\Anaconda\\envs\\BTP\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
            "File \u001b[1;32me:\\Anaconda\\envs\\BTP\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
            "File \u001b[1;32me:\\Anaconda\\envs\\BTP\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32me:\\Anaconda\\envs\\BTP\\Lib\\site-packages\\urllib3\\connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 466\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    468\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
            "File \u001b[1;32me:\\Anaconda\\envs\\BTP\\Lib\\site-packages\\urllib3\\connectionpool.py:1095\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m-> 1095\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mproxy_is_verified:\n",
            "File \u001b[1;32me:\\Anaconda\\envs\\BTP\\Lib\\site-packages\\urllib3\\connection.py:693\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    692\u001b[0m     sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[1;32m--> 693\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    694\u001b[0m     server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[0;32m    695\u001b[0m     tls_in_tls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[1;32me:\\Anaconda\\envs\\BTP\\Lib\\site-packages\\urllib3\\connection.py:199\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03m:return: New socket connection.\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 199\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "File \u001b[1;32me:\\Anaconda\\envs\\BTP\\Lib\\site-packages\\urllib3\\util\\connection.py:60\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeError\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LocationParseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label empty or too long\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     61\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m     62\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32me:\\Anaconda\\envs\\BTP\\Lib\\socket.py:976\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# We override this function since we want to translate the numeric family\u001b[39;00m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;66;03m# and socket type values to enum constants.\u001b[39;00m\n\u001b[0;32m    975\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    977\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m    978\u001b[0m     addrlist\u001b[38;5;241m.\u001b[39mappend((_intenum_converter(af, AddressFamily),\n\u001b[0;32m    979\u001b[0m                      _intenum_converter(socktype, SocketKind),\n\u001b[0;32m    980\u001b[0m                      proto, canonname, sa))\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import os\n",
        "import logging\n",
        "import random\n",
        "import time\n",
        "\n",
        "base_url = 'https://www.ncbi.nlm.nih.gov'\n",
        "search_url = 'https://www.ncbi.nlm.nih.gov/pmc/?term=(Inflammatory+Bowel+Disease%5BTitle%5D)+AND+(Gut+microbiome)'\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "user_agents = [\n",
        "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36',\n",
        "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:86.0) Gecko/20100101 Firefox/86.0',\n",
        "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36',\n",
        "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.3 Safari/605.1.15',\n",
        "]\n",
        "\n",
        "def download_pdf(pdf_url, filename):\n",
        "    headers = {'User-Agent': random.choice(user_agents)}\n",
        "    try:\n",
        "        response = requests.get(pdf_url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        current_dir = os.getcwd()\n",
        "        downloaded_pdfs_dir = os.path.join(current_dir, 'downloaded_pdfs')\n",
        "        os.makedirs(downloaded_pdfs_dir, exist_ok=True)\n",
        "\n",
        "        file_path = os.path.join(downloaded_pdfs_dir, filename)\n",
        "        with open(file_path, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "        logger.warning(f\"Downloaded: {filename}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        logger.error(f\"Error downloading PDF: {pdf_url}\")\n",
        "        logger.error(str(e))\n",
        "\n",
        "def scrape_articles(url, retry_count=3, delay=5, max_pages=4, current_page=1):\n",
        "    headers = {'User-Agent': random.choice(user_agents)}\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        articles = soup.find_all('div', class_='rslt')\n",
        "\n",
        "        for article in articles:\n",
        "            article_url = base_url + article.find('a')['href']\n",
        "            logger.warning(f\"Article URL:{article_url}\")\n",
        "            retry_article = 3\n",
        "            while retry_article > 0:\n",
        "                try:\n",
        "                    article_response = requests.get(article_url, headers=headers)\n",
        "                    article_response.raise_for_status()\n",
        "                    article_soup = BeautifulSoup(article_response.text, 'html.parser')\n",
        "\n",
        "                    pdf_link = article_soup.find('a', href=re.compile(r'\\.pdf$'))\n",
        "\n",
        "                    if pdf_link:\n",
        "                        pdf_url = base_url + pdf_link['href']\n",
        "                        pdf_filename = pdf_link['href'].split('/')[-1]\n",
        "                        download_pdf(pdf_url, pdf_filename)\n",
        "                        logger.warning(f\"Downloaded: {pdf_filename}\")\n",
        "                    else:\n",
        "                        logger.warning(f\"No PDF found for: {article_url}\")\n",
        "\n",
        "                    time.sleep(5)  # Add a random delay between article requests\n",
        "                    break  # Break the loop if the request is successful\n",
        "                except (requests.exceptions.RequestException, ConnectionResetError) as e:\n",
        "                    logger.error(f\"Error processing article: {article_url}\")\n",
        "                    logger.error(str(e))\n",
        "                    retry_article -= 1\n",
        "                    if retry_article > 0:\n",
        "                        logger.warning(f\"Retrying article {article_url} in {delay} seconds...\")\n",
        "                        time.sleep(delay)\n",
        "                    else:\n",
        "                        logger.error(f\"Max retry attempts reached for article: {article_url}. Skipping.\")\n",
        "\n",
        "        # Check pagination and construct the next page URL\n",
        "        if current_page < max_pages:\n",
        "            logger.warning(f\"Current page: {current_page}\")\n",
        "            next_page = current_page + 1  # Increment the current page\n",
        "            logger.warning(f\"Next page: {next_page}\")\n",
        "\n",
        "            # Construct the URL for the next page\n",
        "            next_url = f\"{search_url}&page={next_page}\"\n",
        "            logger.warning(f\"Next URL: {next_url}\")\n",
        "\n",
        "            time.sleep(random.uniform(2, 5))  # Add a random delay before moving to the next page\n",
        "            scrape_articles(next_url, retry_count, delay, max_pages, next_page)\n",
        "\n",
        "    except (requests.exceptions.RequestException, ConnectionResetError) as e:\n",
        "        if retry_count > 0:\n",
        "            logger.warning(f\"Request error occurred. Retrying in {delay} seconds...\")\n",
        "            time.sleep(delay)\n",
        "            scrape_articles(url, retry_count - 1, delay)\n",
        "        else:\n",
        "            logger.error(\"Max retry attempts reached. Skipping this request.\")\n",
        "\n",
        "# Start scraping\n",
        "scrape_articles(search_url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "BTP",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
